{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1554855755718,
     "user": {
      "displayName": "Tenzin Choeden",
      "photoUrl": "https://lh4.googleusercontent.com/-vFJSb1v4qc0/AAAAAAAAAAI/AAAAAAAAAMo/I6QDMXL-icg/s64/photo.jpg",
      "userId": "10107739269952230275"
     },
     "user_tz": 240
    },
    "id": "hOOlJd7Elzz0",
    "outputId": "a8025bf0-3ced-4452-9df3-beeb2f96659f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_library\n",
      "\u001b[31m  Could not find a version that satisfies the requirement python_speech_library (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for python_speech_library\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#The program is divided into two section:\n",
    "#1) Loading, split and converting mfcc and saving it as npz file\n",
    "#2) Setting up the model and running it\n",
    "# This will be our main dataset with two keys: training and validation.\n",
    "# Following Codes were inspired from : https://github.com/jcardente/kaggle_tfspeech/blob/master/src/util.py\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "from python_speech_features import mfcc\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, isfile, join\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "dataset={\n",
    "        'training':[],\n",
    "        'validation':[]:\n",
    "        } \n",
    " \n",
    "# this label array is for later usage in assigning integer values to the labels\n",
    "labels = [] \n",
    "samplerate = 16000\n",
    "\n",
    "audioPath = \"\"\n",
    "for label in listdir(audioPath):\n",
    "  if(not isdir(join(audioPath, label))):\n",
    "    continue\n",
    "  \n",
    "  labels.append(label) #updating our label array\n",
    "  \n",
    "  labelPath = join(audioPath, label)\n",
    "  idx = 0 #using this index we will divide the training and validation set\n",
    "  \n",
    "  for file in listdir(labelPath):\n",
    "    filePath = join(labelPath, file)\n",
    "    \n",
    "    if not(file.endswith('.wav')and isfile(filePath)):\n",
    "      continue\n",
    "     \n",
    "    idx = idx +1\n",
    "    if(idx <1500): #here we are trying to fill in 1500 file for training from each label. Not a good way to split validation\n",
    "      index['training'].append({'label':label, 'file':filePath})\n",
    "    else:\n",
    "      index['validation'].append({'label': label, 'file':filePath})\n",
    "\n",
    "l2i ={l:i for i,l in enumerate(labels)} #assigning each label an integer value\n",
    "\n",
    "\n",
    "for settype in dataset.key():\n",
    "  for example in index[settype]:\n",
    "    \n",
    "    signal, sr = librosa.load(example['file'], sr = samplerate)\n",
    "    \n",
    "    if len(signal) < samplerate: #we need to pad for those sounds with less than 1 sec\n",
    "      pad = np.zeros(samplerate)\n",
    "      start = (len(pad)-len(signal))//2\n",
    "      pad[start:start+samplerate] = signal #we fit our signal inbetween 0's\n",
    "      signal = pad\n",
    "    \n",
    "    if len(signal) > samplerate: #we are cutting those sounds with more than 1 sec\n",
    "      start = (len(signal)- samplerate)//2\n",
    "      signal = signal[start: start+samplerate]\n",
    "    \n",
    "    example['signal'] = signal #adding new key called signal with its value\n",
    "\n",
    "for settype in dataset.key(): #this loop is for converting the signal to mfcc\n",
    "  for example in dataset[settype]:\n",
    "    mfcc_feature =  mfcc(example['signal']) #using the mfcc with its default values\n",
    "    mfcc_std = StandardScaler().fit_transform(mfcc_feat) #standardization\n",
    "    example['mfcc'] = mfcc_std\n",
    "\n",
    "np.savez('training',  dataset['training'])\n",
    "np.savez('validation', dataset['validation'])    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
